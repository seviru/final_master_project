###########################################################################################################
### In this folder we will store our scripts regarding the multiple alignment of the fastas previously  ###
### extracted from our MongoDB                                                                          ###
###########################################################################################################

tree_builder.py: It's a python script which builds a tree for the alignment of a given cluster name.
        USAGE: $python tree_builder.py <CLUSTER NAME> <PARTITION WHERE IT'S STORED>
        NEEDED: Needs FastTree to align. If It isn't found, try: $module load FastTree/2.1.11-GCC-8.2.0-2.31.1

tree_builder.launcher.sh: It's a script used to run our script tree_builder.py in a computation cluster environment.
		USAGE: (Inside the cluster)$sbatch -a 1-<CLUSTER FILE NUMBER OF LINES>%<MAX NUMBER OF TASKS RUNNING AT THE SAME TIME> -o <SLURM OUT FOLDER>/%A_%a.out -e <SLURM ERROR FOLDER>/%A_%a.err -t <HOURS:MINS:SECS DEDICATED TO THE JOB> tree_builder.launcher.sh <FILENAME WITH THE CLUSTER NAMES AND PARTITIONS>
		NEEDED: Already existing folders <SLURM OUT FOLDER> and <SLURM ERROR FOLDER>

tree_builder.sbatch_chunks.sh: It's a script used to run tree_builder.launcher.sh when we have more than 200.000 jobs to launch at once.
		NEEDED: <CHUNKSIZE>: Ammount of jobs that we want to send as if they were the same one.
			<RECORDS>: Number of individual jobs we wouls launch if we didnt group them. $(wc -l ../data/<OUTFILE>.txt | awk '{print $1});
			<JOBS>: Number of jobs we will launch once we have grouped them. $(((records/chunksize)+1));
		USAGE: $sbatch -a 1-${<JOBS>} -t <TIME> -o <SLURM OUT FOLDER>/%A_%a.out -e <SLURM EROR FOLDER>/%A_%a.err ./tree_builder.sbatch_chunks.sh ../data/<OUTFILE>.txt ${<CHUNKSIZE>} ${<RECORDS>} tree_builder.launcher.sh 

tree_builder.cheatsheet.sh: Cheatsheet on how to use aligner.sbatch_chunks.sh
